{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d369a312",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "description: Dealing with AvalancheDatasets\n",
    "---\n",
    "\n",
    "# The AvalancheDataset\n",
    "\n",
    "The `AvalancheDataset` is an implementation of the PyTorch `Dataset` class that comes with many useful out-of-the-box functionalities. For most users, the *AvalancheDataset* can be used as a plain PyTorch Dataset that will return `x, y, t` elements. However, the AvalancheDataset is much more powerful than a simple PyTorch Dataset. \n",
    "\n",
    "\n",
    "**A serie of _Mini How-Tos_** will guide you through the functionalities of the *AvalancheDataset* and its subclasses:\n",
    "\n",
    "- [The AvalancheDataset](https://avalanche.continualai.org/how-tos/avalanche_dataset_preamble) (this page)\n",
    "  - [Preamble](#üéØ-Preamble:-Non-Avalanche-PyTorch-Datasets)\n",
    "- [Creating AvalancheDatasets](https://avalanche.continualai.org/how-tos/avalanche_dataset_how_to/avalanche_dataset_creation)\n",
    "- [Advanced Transformations](https://avalanche.continualai.org/how-tos/avalanche_dataset_how_to/avalanche_dataset_transformations)\n",
    "\n",
    "However, brefore jumping to the *Mini How-To*s, **we recommend having a look at the basic notions of Dataset and DataLoader by reading the following short preamble**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdb4767",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## üéØ Preamble: Non-Avalanche PyTorch Datasets\n",
    "This short preamble will briefly go through the basic notions of Dataset offered natively by PyTorch. A solid grasp of these notions are needed to understand:\n",
    "1. How PyTorch data loading works in general\n",
    "2. How AvalancheDatasets differs from PyTorch Datasets\n",
    "\n",
    "### üìö Dataset: general definition\n",
    "\n",
    "In PyTorch, **a `Dataset` is a class** exposing two methods:\n",
    "- `__len__()`, which returns the amount of instances in the dataset (as an `int`). \n",
    "- `__getitem__(idx)`, which returns the data point at index `idx`.\n",
    "\n",
    "In other words, a Dataset instance is just an object for which, similarly to a list, one can simply:\n",
    "- Obtain its length using the Python `len(dataset)` function.\n",
    "- Obtain a single data point using the `x, y = dataset[idx]` syntax.\n",
    "\n",
    "The content of the dataset can be either loaded in memory when the dataset is instantiated (like the torchvision MNIST dataset does) or, for big datasets like ImageNet, the content is kept on disk, with the dataset keeping the list of files in an internal field. In this case, data is loaded from the storage on-the-fly when `__getitem__(idx)` is called. The way those things are managed is specific to each dataset implementation.\n",
    "\n",
    "### PyTorch Datasets\n",
    "The PyTorch library offers 4 Dataset implementations:\n",
    "- `Dataset`: an interface defining the `__len__` and `__getitem__` methods.\n",
    "- `TensorDataset`: instantiated by passing X and Y tensors. Each row of the X and Y tensors is interpreted as a data point. The `__getitem__(idx)` method will simply return the `idx`-th row of X and Y tensors.\n",
    "- `ConcatDataset`: instantiated by passing a list of datasets. The resulting dataset is a concatenation of those datasets.\n",
    "- `Subset`: instantiated by passing a dataset and a list of indices. The resulting dataset will only contain the data points described by that list of indices.\n",
    "\n",
    "As explained in the mini *How-To*s, Avalanche offers a customized version for all these 4 datasets.\n",
    "\n",
    "### Transformations\n",
    "Most datasets from the *torchvision* libraries (as well as datasets found \"in the wild\") allow for a `transformation` function to be passed to the dataset constructor. The support for transformations is not mandatory for a dataset, but it is quite common to support them. The transformation is used to process the X value of a data point before returning it. This is used to normalize values, apply augmentations, etcetera.\n",
    "\n",
    "As explained in the mini *How-To*s, the `AvalancheDataset` class implements a very rich and powerful set of functionalities for managing transformations.\n",
    "\n",
    "### Quick note on the IterableDataset class\n",
    "A variation of the standard `Dataset` exist in PyTorch: the [IterableDataset](https://pytorch.org/docs/stable/data.html#iterable-style-datasets). When using an `IterableDataset`, one can load the data points in a sequential way only (by using a tape-alike approach). The `dataset[idx]` syntax and `len(dataset)` function are not allowed. **Avalanche does NOT support `IterableDataset`s.** You shouldn't worry about this because, realistically, you will never encounter such datasets.\n",
    "\n",
    "## DataLoader\n",
    "The `Dataset` is a very simple object that only returns one data point given its index. In order to create minibatches and speed-up the data loading process, a `DataLoader` is required.\n",
    "\n",
    "The PyTorch `DataLoader` class is a very efficient mechanism that, given a `Dataset`, will return **minibatches** by optonally **shuffling** data brefore each epoch and by **loading data in parallel** by using multiple workers.\n",
    "\n",
    "## Preamble wrap-up\n",
    "To wrap-up, let's see how the native, *non-Avalanche*, PyTorch components work in practice. In the following code we create a `TensorDataset` and then we load it in minibatches using a `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bce4be3-91ef-4816-9a3f-5c392ef05027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded minibatch of 10 instances\n",
      "Loaded minibatch of 10 instances\n",
      "Loaded minibatch of 10 instances\n",
      "Loaded minibatch of 10 instances\n",
      "Loaded minibatch of 10 instances\n",
      "Loaded minibatch of 10 instances\n",
      "Loaded minibatch of 10 instances\n",
      "Loaded minibatch of 10 instances\n",
      "Loaded minibatch of 10 instances\n",
      "Loaded minibatch of 10 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# Create a dataset of 100 data points described by 22 features + 1 class label\n",
    "x_data = torch.rand(100, 22)\n",
    "y_data = torch.randint(0, 5, (100,))\n",
    "\n",
    "# Create the Dataset\n",
    "my_dataset = TensorDataset(x_data, y_data)\n",
    "\n",
    "# Create the DataLoader\n",
    "my_dataloader = DataLoader(my_dataset, batch_size=10, shuffle=True, num_workers=4)\n",
    "\n",
    "# Run one epoch\n",
    "for x_minibatch, y_minibatch in my_dataloader:\n",
    "    print('Loaded minibatch of', len(x_minibatch), 'instances')\n",
    "# Output: \"Loaded minibatch of 10 instances\" x10 times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f6fdec-f1d0-4cdc-a6e0-6e7c0a6b3be7",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "With these notions in mind, you can start start your journey on understanding the functionalities offered by the AvalancheDatasets by going through the *Mini How-To*s.\n",
    "\n",
    "Refer to the index found at the beginning of this page for the complete [list of the *Mini How-To*s regarding AvalancheDatasets](#The-AvalancheDataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02de0ce4-2711-4832-8b0e-516040483ae5",
   "metadata": {},
   "source": [
    "## ü§ù Run it on Google Colab\n",
    "\n",
    "You can run _this chapter_ and play with it on Google Colaboratory by clicking here: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContinualAI/avalanche/blob/master/notebooks/how-tos/avalanche_dataset_preamble.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
